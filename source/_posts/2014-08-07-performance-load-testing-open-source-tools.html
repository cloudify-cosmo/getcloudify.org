---
layout: blogpost
title: Feeder Feeder Data Eater!
image: nircohen.jpg
author: Nir Cohen
tags: 
 - DevOps
 - Logging
 - Cloud Orchestration
 - Cloud Automation
 - Python
---
<notextile>

<img src="/img/blog/feeder.png" alt="Feeder | Generate Formatted Data - Send + Destroy">
<br/>
<br/>
<h2>A new open source Python module to help you with your performance testing, load testing, configurations, data structure, metrics...you name it.</h2>

<h3><font style="font-weight: bold">Intro</font></h3>

<p>We've all (well.. not ALL…) been in that situation where we need to generate random data for any number of reasons.&#160; For instance, something I kept running into was testing our <a href="http://www.elasticsearch.org/" target="_blank">Elasticsearch</a> node clusters (mappings, config integrity and load) and <a href="http://logstash.net/" target="_blank">logstash</a> filters (inputs, filters, outputs…) . To do so I needed to actually get some logs in there...which is apparently easier said than done.</p>

<p>A good example would be sending logs from your Apache instances across your environment. When you want to test your Apache log filters in logstash, and your Elasticsearch/logstash cluster's susceptibility to high load you might decide to go through the whole process of installing Apache on your multiple instances and start sending Apache logs. Reconfiguring the logger, managing multiple instances to send from different IPs and creating high load, will eventually be tedious to handle.</p>

<p>This is where <a href="http://feeder.readthedocs.org" target="_blank">feeder</a> comes in.</p>

<h3><font style="font-weight: bold">Overview</font></h3>

<p>Feeder is a <a href="https://docs.python.org/2/py-modindex.html" target="_blank">Python module</a> that basically generates random data in different formats and allows you to send it via your transport of choice (for a list of available transports see the <a href="http://feeder.readthedocs.org/en/latest/transports.html" target="_blank">transports</a> section.)&#160; This enables you to test load, performance, configuration, and data structure regularly. Nifty.</p>


<hr>

<span class="pullquote-left">
  <font style="font-weight: bold" size="5" face="Baskerville Old Face"><em>Cloudify 3.0 - deploy thousands of node instances without losing control.</em></font>&nbsp; <a class="btn btn-medium btn-theme btn-rounded" id="downloadBtnInner" href="{{ site.baseurl }}/downloads/get_cloudify.html" target="_blank"><i class="icon-plus"></i> Go </a></span>
  
  <hr>

<h3><font style="font-weight: bold">From Up to Destroy</font></h3>

<p>What feeder means for <a href="{{ site.baseurl }}" target="_blank">Cloudify</a>, is that we're now able to test our Elasticsearch nodes and logstash agents to understand how our system behaves. We can easily create a Vagrant file which automatically loads up some instances with Feeder already running and send our randomly generated, formatted data to our Cloudify manager. Then, when we're done testing them we can just do a <code>vagrant destroy</code>, and we're done.</p>

<h3><font style="font-weight: bold">Mouth</font></h3>

<p>Feeder has a CLI called "mouth", in which you can define a number of different runtime parameters.&#160; </p>

<p>The two main parameters are transports and <a href="http://feeder.readthedocs.org/en/latest/formatters.html">formatters</a>.</p>

<p>Transports are very simple Python classes that define how the data is sent, and formatters are classes which describe how the data is formatted.</p>

<p>In the CLI you can specify:</p>

<ul>
  <li>
    <p>which transport, formatter and config file to use.</p>
  </li>

  <li>
    <p>the number of messages you want to send.</p>
  </li>

  <li>
    <p>the time gap between batches.</p>
  </li>

  <li>
    <p>the batch size (i.e. the number of messages to send simultaneously).</p>
  </li>
</ul>

<h3><font style="font-weight: bold">Configuration</font></h3>

<p>To define your own format and data that you want to use, and the transport's configuration, you use a Python dict based configuration file. </p>

<p>Two basic formatters are supplied alongside some additional, application-specific formatters (and more are in the planning). </p>

<ul>
  <li>
    <p>The <a href="http://feeder.readthedocs.org/en/latest/formatter_custom.html" target="_blank">Custom</a> formatter lets you define the exact format for your data and supplies two methods for defining the data itself - use the special $RAND variable that will tell feeder to randomize the data for a specific field in your format, or define your own, static data set.</p>
  </li>

  <li>
    <p>The <a href="http://feeder.readthedocs.org/en/latest/formatter_json.html" target="_blank">JSON</a> formatter requires setting the data only. A set of fields and their corresponding data objects.</p>
  </li>
</ul>

<p>For transports, configuration depends on the transport type. Using the UDP transport, for instance, will require you to define the host and the port you want to send to.&#160; </p>

<h3><font style="font-weight: bold">Feeder in Cloudify</font></h3>

<p>With Cloudify, this will now be our primary tool to test our monitoring and logging architecture, which before required a lot more manual labor and time investment. I'm also hoping that it will be used to test our REST API load and ability to withstand problematic requests.</p>

<h3><font style="font-weight: bold">Use Case</font></h3>

<p>Feeder is not only about testing logging pipelines...in the docs you'll be able to find an excellent use case on how to use Feeder to feed metrics. Feeder can actually be used to send any type of data via any type of transport by writing very little code.</p>

<p>I'll just set the scene and then let you read the rest.</p>

<p>Let's say you're leading a monitoring project, where you need to build your first Graphite cluster, </p>

<p>and transport your metrics via AMQP.&#160; You have your <a href="http://www.rabbitmq.com/" target="_blank">RabbitMQ</a> cluster installed and Graphite is ready to pull metrics, but it's important that you feed multiple metrics with multiple values and multiple namespaces to test the integrity of your cluster's configuration and performance.&#160; But you want to do all this without having to install <a href="https://github.com/etsy/statsd/" target="_blank">StatsD</a> or <a href="https://github.com/BrightcoveOS/Diamond" target="_blank">Diamond</a> on all of your instances and configure them to send metrics... and then find out that your configuration is incorrect and iterate over it 11 times…</p>

<p>This is the sort of scenario Feeder comes to solve - complex testing scenarios - where you want to send metrics from two availability zones, three types of middleware servers, where each have three base metric types, each with average and max measurements.&#160; Now you can - read the full <a href="http://feeder.readthedocs.org/en/latest/case_study.html" target="_blank">use case</a> and <a href="http://github.com/nir0s/feeder" target="_blank">see the code</a>.</p>

<p>If you're interested in contributing formatters and transports to the project you can fork the repo, and have fun.</p>
</notextile>